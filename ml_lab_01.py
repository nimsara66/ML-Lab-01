# -*- coding: utf-8 -*-
"""ML Lab 01.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dPvDF7VtVUn6vrWPwVGsdZzPAd-jYNrz

# Import Dataset
"""

import pandas as pd

csv_url = "/content/drive/MyDrive/#Semester07/train.csv"
data = pd.read_csv(csv_url)

print(data.head())  # Display the first few rows of the DataFrame

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score, accuracy_score
from sklearn.model_selection import train_test_split

"""# For Label 1"""

X = data.iloc[:, :256]  # Select first 256 columns as features
y = data.iloc[:, 256]    # Select the 257th column as labels

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=2021)
print(X_train.shape)
print(X_test.shape)

print(X.shape)

import pandas as pd
from sklearn.ensemble import IsolationForest

# Train a RandomForestClassifier for outlier detection
outlier_detector = IsolationForest(contamination=0.05)

# Fit the model and predict outlier labels
outlier_labels = outlier_detector.fit_predict(X_train)

# Remove outliers from the dataset
X_train_no_outliers = X_train[outlier_labels == 1]
y_train_no_outliers = y_train[outlier_labels == 1]

print(X_train_no_outliers.shape)
print(y_train_no_outliers.shape)

X_train = X_train_no_outliers
y_train = y_train_no_outliers

outlier_labelss = outlier_detector.fit_predict(X)

# Remove outliers from the dataset
X_no_outliers = X[outlier_labelss == 1]

print(X.shape)
print(X_no_outliers.shape)
print(X.shape[0]-X_no_outliers.shape[0])

# %% Fit blackbox model
rf_train = RandomForestClassifier()
rf_train.fit(X_train, y_train)
y_pred_train = rf_train.predict(X_train)
print(f"F1 Score for train set {f1_score(y_train, y_pred_train, average='macro')}")
print(f"Accuracy for train set {accuracy_score(y_train, y_pred_train)}")

y_pred_test = rf_train.predict(X_test)
print(f"F1 Score for test set {f1_score(y_test, y_pred_test, average='macro')}")
print(f"Accuracy for test set {accuracy_score(y_test, y_pred_test)}")

import numpy as np

# Identifying Correlated Features
correlation_matrix = data.corr()
correlation_matrix

# Save the correlation matrix to a CSV file
# correlation_matrix.to_csv("correlation_matrix.csv", index=True)

# Set the correlation threshold
correlation_threshold = 0.6  # You can adjust this threshold as needed

# Filter out correlations above the threshold
high_correlations = correlation_matrix.abs() > correlation_threshold

# Create a mask to hide the diagonal elements (self-correlations)
mask = np.triu(np.ones(high_correlations.shape), k=1)

# Apply the mask to the high_correlations DataFrame
high_correlations = high_correlations & mask

# Get the list of features with high correlations
high_correlation_features = [col for col in high_correlations.columns if any(high_correlations[col])]

print("Features with high correlations:", high_correlation_features)

# Visualize Correlation Heatmap
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm")
plt.show()

# Identifying Duplicated Features
duplicated_rows = data.duplicated()
duplicated_features = data.T.duplicated()

# Save the correlation matrix to a CSV file
duplicated_features.to_csv("duplicated_features.csv", index=True)

print(f"duplicated_rows: {duplicated_rows}")
print(f"duplicated_features: {duplicated_features}")

# %% Imports
# !pip install shap
import shap

# %% Create SHAP explainer
explainer = shap.TreeExplainer(rf_train)
# Calculate shapley values for test data
start_index = 1
end_index = 2
shap_values = explainer.shap_values(X_test[start_index:end_index])
X_test[start_index:end_index]

print(shap_values[0].shape)
shap_values

# %% >> Visualize local predictions
shap.initjs()
# Force plot
prediction = rf_train.predict(X_test[start_index:end_index])[0]
print(f"The RF predicted: {prediction}")
shap.force_plot(explainer.expected_value[1],
                shap_values[1],
                X_test[start_index:end_index]) # for values

# %% >> Visualize global features
# Feature summary
shap.summary_plot(shap_values, X_test)

# Calculate the absolute values of SHAP values
abs_shap_values = np.abs(shap_values[1])

# Create a dictionary mapping feature indices to their corresponding absolute SHAP values
feature_abs_shap_dict = {feature_index: abs_shap for feature_index, abs_shap in enumerate(abs_shap_values[0])}

# Sort the features based on their absolute SHAP values in ascending order
sorted_features = sorted(feature_abs_shap_dict, key=feature_abs_shap_dict.get, reverse=True)

# Get the 60 features with the most contribution
most_contributed_features = sorted_features[:60]

print("Features with the most contribution:")
for feature_index in most_contributed_features:
    print(f"Index {feature_index}: {X_test[start_index:end_index].iloc[0, feature_index]} (SHAP value: {feature_abs_shap_dict[feature_index]})")

# filtered_high_correlation_features = [item for item in high_correlation_features if not item.startswith("label_")]
# drop_features_list = [f'feature_{index+1}' for index in least_contributed_features] + filtered_high_correlation_features
# drop_features_list = list(dict.fromkeys(drop_features_list))

# X_after = X.drop(columns=drop_features_list)

# Xaf_train, Xaf_test, yaf_train, yaf_test = train_test_split(X_after, y, test_size=0.20, random_state=2021)
# print(Xaf_train.shape)
# print(Xaf_test.shape)

filtered_high_correlation_features = [feature_index for feature_index in most_contributed_features if f'feature_{feature_index+1}' not in high_correlation_features]

# X_after = X.drop(columns=drop_features_list)
X_after = X.iloc[:, filtered_high_correlation_features]

Xaf_train, Xaf_test, yaf_train, yaf_test = train_test_split(X_after, y, test_size=0.20, random_state=2021)
print(Xaf_train.shape)
print(Xaf_test.shape)

# %% Fit blackbox model
rfaf_train = RandomForestClassifier()
rfaf_train.fit(Xaf_train, yaf_train)
yaf_pred_train = rfaf_train.predict(Xaf_train)
print(f"F1 Score for train set {f1_score(yaf_train, yaf_pred_train, average='macro')}")
print(f"Accuracy for train set {accuracy_score(yaf_train, yaf_pred_train)}")

yaf_pred_test = rfaf_train.predict(Xaf_test)
print(f"F1 Score for test set {f1_score(yaf_test, yaf_pred_test, average='macro')}")
print(f"Accuracy for test set {accuracy_score(yaf_test, yaf_pred_test)}")

csv_url = "/content/drive/MyDrive/#Semester07/test.csv"
test = pd.read_csv(csv_url)

print(test.head())  # Display the first few rows of the DataFrame

X_t = test.iloc[:, :256]  # Select first 256 columns as features
y_pred_t = rf_train.predict(X_t)
y_pred_t

X_t_after = X_t.iloc[:, filtered_high_correlation_features]
yaf_pred_t = rfaf_train.predict(X_t_after)
yaf_pred_t

# Assuming the prediction with all the features is actual label
print(f"F1 Score for test set {f1_score(y_pred_t, yaf_pred_t, average='macro')}")
print(f"Accuracy for test set {accuracy_score(y_pred_t, yaf_pred_t)}")

# Combine predicted labels and convert them to DataFrames
# y_pred_t_df = pd.DataFrame({'Predicted labels before feature engineering': y_pred_t})
# yaf_pred_t_df = pd.DataFrame({'Predicted labels after feature engineering': yaf_pred_t})

# Rename columns in X_t_after with the 'new_feature_{i}' format
# X_t_combined = X_t_after.copy()

# index = 1
# for i, col in enumerate(X_t_after.columns, start=1):
#     X_t_combined.rename(columns={col: f'new_feature_{index}'}, inplace=True)
#     index+=1

# # Combine all DataFrames horizontally (axis=1)
# combined_df = pd.concat([y_pred_t_df, yaf_pred_t_df, X_t_combined], axis=1)

# # Write the combined dataset to a CSV file
# combined_df.to_csv('190175X_label_1.csv', index=False)

y_pred_t_df = pd.DataFrame({'Predicted labels before feature engineering': y_pred_t})
yaf_pred_t_df = pd.DataFrame({'Predicted labels after feature engineering': yaf_pred_t})
new_features_df = pd.DataFrame({'No of new features': [X_t_after.shape[1]] * X_t_after.shape[0]})

sorted_columns = sorted(X_t_after.columns, key=lambda x: int(x.split('_')[-1]))
X_t_after = X_t_after[sorted_columns]
X_t_after.columns = ['new_' + col for col in X_t_after.columns]

# Combine all DataFrames horizontally (axis=1)
combined_df = pd.concat([y_pred_t_df, yaf_pred_t_df, new_features_df, X_t_after], axis=1)

# Write the combined dataset to a CSV file
combined_df.to_csv('190175X_label_1.csv', index=False)

"""# For Label 3

"""

X3 = data.iloc[:, :256]  # Select first 256 columns as features
y3 = data.iloc[:, 258]    # Select the 257th column as labels

X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.20, random_state=2021)
print(X3_train.shape)
print(X3_test.shape)

# %% Fit blackbox model
rf3_train = RandomForestClassifier()
rf3_train.fit(X3_train, y3_train)
y3_pred_train = rf3_train.predict(X3_train)
print(f"F1 Score for train set {f1_score(y3_train, y3_pred_train, average='macro')}")
print(f"Accuracy for train set {accuracy_score(y3_train, y3_pred_train)}")

y3_pred_test = rf3_train.predict(X_test)
print(f"F1 Score for test set {f1_score(y3_test, y3_pred_test, average='macro')}")
print(f"Accuracy for test set {accuracy_score(y3_test, y3_pred_test)}")

# %% Create SHAP explainer
explainer3 = shap.TreeExplainer(rf3_train)
# Calculate shapley values for test data
start_index = 1
end_index = 2
shap_values3 = explainer3.shap_values(X3_test[start_index:end_index])
X3_test[start_index:end_index]

print(shap_values3[0].shape)
shap_values3

# %% >> Visualize local predictions
shap.initjs()
# Force plot
prediction3 = rf3_train.predict(X3_test[start_index:end_index])[0]
print(f"The RF predicted: {prediction3}")
shap.force_plot(explainer3.expected_value[1],
                shap_values3[1],
                X3_test[start_index:end_index]) # for values

# Calculate the absolute values of SHAP values
abs_shap_values3 = np.abs(shap_values3[1])

# Create a dictionary mapping feature indices to their corresponding absolute SHAP values
feature_abs_shap_dict3 = {feature_index: abs_shap for feature_index, abs_shap in enumerate(abs_shap_values3[0])}

# Sort the features based on their absolute SHAP values in ascending order
sorted_features3 = sorted(feature_abs_shap_dict3, key=feature_abs_shap_dict3.get, reverse=True)

# Get the 60 features with the most contribution
most_contributed_features3 = sorted_features3[:60]

print("Features with the most contribution:")
for feature_index in most_contributed_features3:
    print(f"Index {feature_index}: {X3_test[start_index:end_index].iloc[0, feature_index]} (SHAP value: {feature_abs_shap_dict3[feature_index]})")

filtered_high_correlation_features3 = [feature_index for feature_index in most_contributed_features3 if f'feature_{feature_index+1}' not in high_correlation_features]

# X_after = X.drop(columns=drop_features_list)
X3_after = X3.iloc[:, filtered_high_correlation_features3]

X3af_train, X3af_test, y3af_train, y3af_test = train_test_split(X3_after, y3, test_size=0.20, random_state=2021)
print(X3af_train.shape)
print(X3af_test.shape)

# %% Fit blackbox model
rfaf3_train = RandomForestClassifier()
rfaf3_train.fit(X3af_train, y3af_train)
y3af_pred_train = rfaf3_train.predict(X3af_train)
print(f"F1 Score for train set {f1_score(y3af_train, y3af_pred_train, average='macro')}")
print(f"Accuracy for train set {accuracy_score(y3af_train, y3af_pred_train)}")

y3af_pred_test = rfaf3_train.predict(X3af_test)
print(f"F1 Score for test set {f1_score(y3af_test, y3af_pred_test, average='macro')}")
print(f"Accuracy for test set {accuracy_score(y3af_test, y3af_pred_test)}")

y3af_train

csv_url = "/content/drive/MyDrive/#Semester07/test.csv"
test = pd.read_csv(csv_url)

print(test.head())  # Display the first few rows of the DataFrame

X3_t = test.iloc[:, :256]  # Select first 256 columns as features
y3_pred_t = rf3_train.predict(X3_t)
y3_pred_t

X3_t_after = X3_t.iloc[:, filtered_high_correlation_features3]
y3af_pred_t = rfaf3_train.predict(X3_t_after)
y3af_pred_t

# Assuming the prediction with all the features is actual label
print(f"F1 Score for test set {f1_score(y3_pred_t, y3af_pred_t, average='macro')}")
print(f"Accuracy for test set {accuracy_score(y3_pred_t, y3af_pred_t)}")

# # Combine predicted labels and convert them to DataFrames
# y3_pred_t_df = pd.DataFrame({'Predicted labels before feature engineering': y3_pred_t})
# y3af_pred_t_df = pd.DataFrame({'Predicted labels after feature engineering': y3af_pred_t})

# # Rename columns in X_t_after with the 'new_feature_{i}' format
# X3_t_combined = X3_t_after.copy()

# index = 1
# for i, col in enumerate(X3_t_after.columns, start=1):
#     X3_t_combined.rename(columns={col: f'new_feature_{index}'}, inplace=True)
#     index+=1

# # Combine all DataFrames horizontally (axis=1)
# combined_df3 = pd.concat([y3_pred_t_df, y3af_pred_t_df, X3_t_combined], axis=1)

# # Write the combined dataset to a CSV file
# combined_df3.to_csv('190175X_label_3.csv', index=False)

y3_pred_t_df = pd.DataFrame({'Predicted labels before feature engineering': y3_pred_t})
y3af_pred_t_df = pd.DataFrame({'Predicted labels after feature engineering': y3af_pred_t})
new_features3_df = pd.DataFrame({'No of new features': [X3_t_after.shape[1]] * X3_t_after.shape[0]})

sorted3_columns = sorted(X3_t_after.columns, key=lambda x: int(x.split('_')[-1]))
X3_t_after = X3_t_after[sorted3_columns]
X3_t_after.columns = ['new_' + col for col in X3_t_after.columns]

# Combine all DataFrames horizontally (axis=1)
combined3_df = pd.concat([y3_pred_t_df, y3af_pred_t_df, new_features3_df, X3_t_after], axis=1)

# Write the combined dataset to a CSV file
combined3_df.to_csv('190175X_label_3.csv', index=False)

"""# For Label 4"""

# label 4 column is not equally distributed
from imblearn.over_sampling import RandomOverSampler

oversample = RandomOverSampler(sampling_strategy='minority')

# Convert to numpy and oversample
X4 = data.iloc[:, :256]  # Select first 256 columns as features
y4 = data.iloc[:, 259]    # Select the 257th column as labels
X4_np = data.iloc[:, :256].to_numpy()
y4_np = data.iloc[:, 259].to_numpy()
X4_np, y4_np = oversample.fit_resample(X4_np, y4_np)

# Convert back to pandas
X4_over = pd.DataFrame(X4_np, columns=X4.columns)
y4_over = pd.Series(y4_np, name=y4.name)

print(X4_over.shape)
print(y4_over.shape)

y4_over

X4_train, X4_test, y4_train, y4_test = train_test_split(X4_over, y4_over, test_size=0.20, random_state=2021)
print(X4_train.shape)
print(X4_test.shape)

# %% Fit blackbox model
rf4_train = RandomForestClassifier()
rf4_train.fit(X4_train, y4_train)
y4_pred_train = rf4_train.predict(X4_train)
print(f"F1 Score for train set {f1_score(y4_train, y4_pred_train, average='macro')}")
print(f"Accuracy for train set {accuracy_score(y4_train, y4_pred_train)}")

y4_pred_test = rf4_train.predict(X4_test)
print(f"F1 Score for test set {f1_score(y4_test, y4_pred_test, average='macro')}")
print(f"Accuracy for test set {accuracy_score(y4_test, y4_pred_test)}")

# %% Create SHAP explainer
explainer4 = shap.TreeExplainer(rf4_train)
# Calculate shapley values for test data
start_index = 1
end_index = 2
shap_values4 = explainer4.shap_values(X4_test[start_index:end_index], check_additivity=False)
X4_test[start_index:end_index]

print(shap_values4[0].shape)
shap_values4

# %% >> Visualize local predictions
shap.initjs()
# Force plot
prediction4 = rf4_train.predict(X4_test[start_index:end_index])[0]
print(f"The RF predicted: {prediction4}")
shap.force_plot(explainer4.expected_value[1],
                shap_values4[1],
                X_test[start_index:end_index]) # for values

# %% >> Visualize global features
# Feature summary
shap.summary_plot(shap_values4, X4_test)

import numpy as np

# Calculate the absolute values of SHAP values
abs_shap_values4 = np.abs(shap_values4[1])

# Create a dictionary mapping feature indices to their corresponding absolute SHAP values
feature_abs_shap_dict4 = {feature_index: abs_shap for feature_index, abs_shap in enumerate(abs_shap_values4[0])}

# Sort the features based on their absolute SHAP values in ascending order
sorted_features4 = sorted(feature_abs_shap_dict4, key=feature_abs_shap_dict4.get, reverse=True)

# Get the 60 features with the most contribution
most_contributed_features4 = sorted_features4[:60]

print("Features with the most contribution:")
for feature_index in most_contributed_features4:
    print(f"Index {feature_index}: {X4_test[start_index:end_index].iloc[0, feature_index]} (SHAP value: {feature_abs_shap_dict4[feature_index]})")

filtered_high_correlation_features4 = [feature_index for feature_index in most_contributed_features4 if f'feature_{feature_index+1}' not in high_correlation_features]

# X_after = X.drop(columns=drop_features_list)
X4_after = X4_over.iloc[:, filtered_high_correlation_features4]

X4af_train, X4af_test, y4af_train, y4af_test = train_test_split(X4_after, y4_over, test_size=0.20, random_state=2021)
print(X4af_train.shape)
print(X4af_test.shape)

# %% Fit blackbox model
rfaf4_train = RandomForestClassifier()
rfaf4_train.fit(X4af_train, y4af_train)
y4af_pred_train = rfaf4_train.predict(X4af_train)
print(f"F1 Score for train set {f1_score(y4af_train, y4af_pred_train, average='macro')}")
print(f"Accuracy for train set {accuracy_score(y4af_train, y4af_pred_train)}")

y4af_pred_test = rfaf4_train.predict(X4af_test)
print(f"F1 Score for test set {f1_score(y4af_test, y4af_pred_test, average='macro')}")
print(f"Accuracy for test set {accuracy_score(y4af_test, y4af_pred_test)}")

csv_url = "/content/drive/MyDrive/#Semester07/test.csv"
test = pd.read_csv(csv_url)

print(test.head())  # Display the first few rows of the DataFrame

X4_t = test.iloc[:, :256]  # Select first 256 columns as features
y4_pred_t = rf4_train.predict(X4_t)
y4_pred_t

X4_t_after = X4_t.iloc[:, filtered_high_correlation_features4]
y4af_pred_t = rfaf4_train.predict(X4_t_after)
y4af_pred_t

# Assuming the prediction with all the features is actual label
print(f"F1 Score for test set {f1_score(y4_pred_t, y4af_pred_t, average='macro')}")
print(f"Accuracy for test set {accuracy_score(y4_pred_t, y4af_pred_t)}")

# # Combine predicted labels and convert them to DataFrames
# y4_pred_t_df = pd.DataFrame({'Predicted labels before feature engineering': y4_pred_t})
# y4af_pred_t_df = pd.DataFrame({'Predicted labels after feature engineering': y4af_pred_t})

# # Rename columns in X_t_after with the 'new_feature_{i}' format
# X4_t_combined = X4_t_after.copy()

# index = 1
# for i, col in enumerate(X4_t_after.columns, start=1):
#     X4_t_combined.rename(columns={col: f'new_feature_{index}'}, inplace=True)
#     index+=1

# # Combine all DataFrames horizontally (axis=1)
# combined_df4 = pd.concat([y4_pred_t_df, y4af_pred_t_df, X4_t_combined], axis=1)

# # Write the combined dataset to a CSV file
# combined_df4.to_csv('190175X_label_4.csv', index=False)

y4_pred_t_df = pd.DataFrame({'Predicted labels before feature engineering': y4_pred_t})
y4af_pred_t_df = pd.DataFrame({'Predicted labels after feature engineering': y4af_pred_t})
new_features4_df = pd.DataFrame({'No of new features': [X4_t_after.shape[1]] * X4_t_after.shape[0]})

sorted4_columns = sorted(X4_t_after.columns, key=lambda x: int(x.split('_')[-1]))
X4_t_after = X4_t_after[sorted4_columns]
X4_t_after.columns = ['new_' + col for col in X4_t_after.columns]
# Combine all DataFrames horizontally (axis=1)
combined4_df = pd.concat([y4_pred_t_df, y4af_pred_t_df, new_features4_df, X4_t_after], axis=1)

# Write the combined dataset to a CSV file
combined4_df.to_csv('190175X_label_4.csv', index=False)

"""# For Label 2"""

selected_column_name = 'label_2'

# Check for missing values in the selected column
missing_values = data[selected_column_name].isna()

# Print the result
if missing_values.any():
    print(f"The column '{selected_column_name}' has missing values.")
else:
    print(f"The column '{selected_column_name}' has no missing values.")

X2 = data.iloc[:, :256]  # Select first 256 columns as features
y2 = data.iloc[:, 257]    # Select the 257th column as labels

# Identify rows with missing values in y2
missing_rows = y2.isnull()

# Step 1: Extract rows with missing values
X2_missing = X2[missing_rows]
y2_missing = y2[missing_rows]

y2_missing

# Step 2: Train a new model after removing missing value rows
X2_clean = X2[~missing_rows]
y2_clean = y2[~missing_rows]

rf2_clean = RandomForestClassifier()
rf2_clean.fit(X2_clean, y2_clean)

# Step 3: Predict missing y4 values
y2_pred_missing = rf2_clean.predict(X2_missing)

# Step 4: Re-train the model with predicted missing y2 values
X2_final = pd.concat([X2_clean, X2_missing])
y2_final = pd.concat([y2_clean, pd.Series(y2_pred_missing, index=X2_missing.index)])

X2_train, X2_test, y2_train, y2_test = train_test_split(X2_final, y2_final, test_size=0.20, random_state=2021)
print(X2_train.shape)
print(X2_test.shape)

rf2_train = RandomForestClassifier()
rf2_train.fit(X2_train, y2_train)

# Evaluate the final model
y2_pred_train = rf2_train.predict(X2_train)
print(f"F1 Score for train set {f1_score(y2_train, y2_pred_train, average='macro')}")
print(f"Accuracy for train set {accuracy_score(y2_train, y2_pred_train)}")

y2_pred_test = rf2_train.predict(X2_test)
print(f"F1 Score for test set {f1_score(y2_test, y2_pred_test, average='macro')}")
print(f"Accuracy for test set {accuracy_score(y2_test, y2_pred_test)}")

# %% Create SHAP explainer
explainer2 = shap.TreeExplainer(rf2_train)
# Calculate shapley values for test data
start_index = 1
end_index = 2
shap_values2 = explainer2.shap_values(X2_test[start_index:end_index])
X2_test[start_index:end_index]

print(shap_values2[0].shape)
shap_values2

# %% >> Visualize local predictions
shap.initjs()
# Force plot
prediction2 = rf2_train.predict(X2_test[start_index:end_index])[0]
print(f"The RF predicted: {prediction2}")
shap.force_plot(explainer2.expected_value[1],
                shap_values2[1],
                X2_test[start_index:end_index]) # for values

# %% >> Visualize global features
# Feature summary
shap.summary_plot(shap_values2, X2_test)

# Calculate the absolute values of SHAP values
abs_shap_values2 = np.abs(shap_values2[1])

# Create a dictionary mapping feature indices to their corresponding absolute SHAP values
feature_abs_shap_dict2 = {feature_index: abs_shap for feature_index, abs_shap in enumerate(abs_shap_values2[0])}

# Sort the features based on their absolute SHAP values in ascending order
sorted_features2 = sorted(feature_abs_shap_dict2, key=feature_abs_shap_dict2.get, reverse=True)

# Get the 60 features with the most contribution
most_contributed_features2 = sorted_features2[:60]

print("Features with the most contribution:")
for feature_index in most_contributed_features2:
    print(f"Index {feature_index}: {X2_test[start_index:end_index].iloc[0, feature_index]} (SHAP value: {feature_abs_shap_dict2[feature_index]})")

filtered_high_correlation_features2 = [feature_index for feature_index in most_contributed_features2 if f'feature_{feature_index+1}' not in high_correlation_features]

# X_after = X.drop(columns=drop_features_list)
X2_after = X2_final.iloc[:, filtered_high_correlation_features2]

X2af_train, X2af_test, y2af_train, y2af_test = train_test_split(X2_after, y2_final, test_size=0.20, random_state=2021)
print(X2af_train.shape)
print(X2af_test.shape)

# %% Fit blackbox model
rfaf2_train = RandomForestClassifier()
rfaf2_train.fit(X2af_train, y2af_train)
y2af_pred_train = rfaf2_train.predict(X2af_train)
print(f"F1 Score for train set {f1_score(y2af_train, y2af_pred_train, average='macro')}")
print(f"Accuracy for train set {accuracy_score(y2af_train, y2af_pred_train)}")

y2af_pred_test = rfaf2_train.predict(X2af_test)
print(f"F1 Score for test set {f1_score(y2af_test, y2af_pred_test, average='macro')}")
print(f"Accuracy for test set {accuracy_score(y2af_test, y2af_pred_test)}")

csv_url = "/content/drive/MyDrive/#Semester07/test.csv"
test = pd.read_csv(csv_url)

print(test.head())  # Display the first few rows of the DataFrame

X2_t = test.iloc[:, :256]  # Select first 256 columns as features
y2_pred_t = rf2_train.predict(X2_t)
y2_pred_t

X2_t_after = X2_t.iloc[:, filtered_high_correlation_features2]
y2af_pred_t = rfaf2_train.predict(X2_t_after)
y2af_pred_t

# Assuming the prediction with all the features is actual label
print(f"F1 Score for test set {f1_score(y2_pred_t, y2af_pred_t, average='macro')}")
print(f"Accuracy for test set {accuracy_score(y2_pred_t, y2af_pred_t)}")

# Combine predicted labels and convert them to DataFrames
y2_pred_t_df = pd.DataFrame({'Predicted labels before feature engineering': y2_pred_t})
y2af_pred_t_df = pd.DataFrame({'Predicted labels after feature engineering': y2af_pred_t})

# Rename columns in X_t_after with the 'new_feature_{i}' format
X2_t_combined = X2_t_after.copy()

index = 1
for i, col in enumerate(X2_t_after.columns, start=1):
    X2_t_combined.rename(columns={col: f'new_feature_{index}'}, inplace=True)
    index+=1

# Combine all DataFrames horizontally (axis=1)
combined_df2 = pd.concat([y2_pred_t_df, y2af_pred_t_df, X2_t_combined], axis=1)

# Write the combined dataset to a CSV file
combined_df2.to_csv('190175X_label_2.csv', index=False)

y2_pred_t_df = pd.DataFrame({'Predicted labels before feature engineering': y2_pred_t})
y2af_pred_t_df = pd.DataFrame({'Predicted labels after feature engineering': y2af_pred_t})
new_features2_df = pd.DataFrame({'No of new features': [X2_t_after.shape[1]] * X2_t_after.shape[0]})

sorted2_columns = sorted(X2_t_after.columns, key=lambda x: int(x.split('_')[-1]))
X2_t_after = X2_t_after[sorted2_columns]
X2_t_after.columns = ['new_' + col for col in X2_t_after.columns]
# Combine all DataFrames horizontally (axis=1)
combined2_df = pd.concat([y2_pred_t_df, y2af_pred_t_df, new_features2_df, X2_t_after], axis=1)

# Write the combined dataset to a CSV file
combined2_df.to_csv('190175X_label_2.csv', index=False)